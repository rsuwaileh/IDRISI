{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training CRF-based LMR model for IDRISI-R datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import SentenceGetter as SG\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn_crfsuite.metrics import flat_classification_report\n",
    "\n",
    "import scipy.stats\n",
    "import nltk\n",
    "import sklearn\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_name):\n",
    "    data = pd.read_csv(file_name, encoding=\"utf-8\")\n",
    "    data = data.fillna(method=\"ffill\")\n",
    "    words = list(set(data[\"Word\"].values))\n",
    "    tags = list(set(data[\"Tag\"].values))\n",
    "    getter = SG.SentenceGetter(data)\n",
    "    sent, pos, tag = getter.get_next()\n",
    "    sentences = getter.sentences\n",
    "    return sentences, words, tags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Feature preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent) - 1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train and test the CRF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_crf(X, y, cv, algorithm, c1, c2, max_iterations):#, all_possible_transitions):\n",
    "    crf = CRF(algorithm=algorithm, c1=c1, c2=c2, \n",
    "              max_iterations=max_iterations)#, \n",
    "    pred = cross_val_predict(estimator=crf, X=X, y=y, cv=cv)\n",
    "    crf.fit(X, y)\n",
    "    return crf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_predict(crf, X_test):   \n",
    "    return crf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Write Predictions to files in BIO-like format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_predictions(output_path, tokens, labels):\n",
    "    writer = open(output_path, 'w', encoding='utf-8', newline=\"\")\n",
    "    \n",
    "    for i in range(len(labels)):\n",
    "        t = [x for x, y, z in tokens[i]]\n",
    "        for j in range(len(labels[i])):\n",
    "            writer.write(t[j] + \"\\t\" + labels[i][j] + \"\\n\")\n",
    "        writer.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driver Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(event, train_path, test_path, out_path):\n",
    "    \n",
    "    sentences_tr, words_tr, tags_tr = read_data(train_path)\n",
    "    sentences_te, words_te, tags_te = read_data(test_path)\n",
    "\n",
    "    X_train = [sent2features(s) for s in sentences_tr] \n",
    "    y_train = [sent2labels(s) for s in sentences_tr] \n",
    "    X_test = [sent2features(s) for s in sentences_te]\n",
    "    y_test = [sent2labels(s) for s in sentences_te]\n",
    "\n",
    "    crf = train_crf(X_train, y_train, 5, 'lbfgs', 0, 1, 100) #default parameters\n",
    "    y_pred = crf.predict(X_test)\n",
    "            \n",
    "    dump_predictions(out_path, sentences_te, y_pred)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `TODO` run the `prepare-data-4CRF` notebook before running this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"<path to IDRISI data directory>\\\\IDRISI\\\\data\\\\LMR\\\\\"\n",
    "\n",
    "events = [\"california_wildfires_2018\", \"canada_wildfires_2016\", \"cyclone_idai_2019\", \"ecuador_earthquake_2016\", \n",
    "          \"greece_wildfires_2018\", \"hurricane_dorian_2019\", \"hurricane_florence_2018\", \"hurricane_harvey_2017\", \n",
    "          \"hurricane_irma_2017\", \"hurricane_maria_2017\", \"hurricane_matthew_2016\", \"italy_earthquake_aug_2016\", \n",
    "          \"kaikoura_earthquake_2016\", \"kerala_floods_2018\", \"maryland_floods_2018\", \"midwestern_us_floods_2019\", \n",
    "          \"pakistan_earthquake_2019\", \"puebla_mexico_earthquake_2017\", \"srilanka_floods_2017\"]\n",
    "\n",
    "  \n",
    "for typ in ['typefull', 'typeless']:\n",
    "    for case in ['random', 'timebased']:\n",
    "        for event in events:\n",
    "            in_path = path + \"EN\\gold-\" + case + \"-bilou-crf\\\\\" + typ + \"\\\\\" + event \n",
    "            train_path = in_path + \"\\\\train.csv\"\n",
    "            test_path = in_path + \"\\\\dev.csv\"\n",
    "            out_path = path + \"EN\\gold-\" + case + \"-bilou-crf\\\\\" + typ + \"\\\\\" + event + \"-predictions.txt\"\n",
    "            run(event, train_path, test_path, out_path)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
