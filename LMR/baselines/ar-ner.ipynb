{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running CaMEL NER models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camel_tools.ner import NERecognizer\n",
    "from camel_tools.tokenizers.word import simple_word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_annotated_data(path):\n",
    "    tokens = []\n",
    "    labels = []\n",
    "    t = []\n",
    "    l = []\n",
    "    \n",
    "    for token in open(path, encoding='utf-8').read().splitlines(): \n",
    "        if token == '':\n",
    "            tokens.append(t)\n",
    "            labels.append(l)\n",
    "            t = []\n",
    "            l = []\n",
    "            continue\n",
    "        splits = token.split()\n",
    "        t.append(splits[0])\n",
    "        l.append(splits[1])\n",
    "        \n",
    "    if len(t) > 0 and len(l) > 0:\n",
    "        tokens.append(t)\n",
    "        labels.append(l)\n",
    "        \n",
    "    return tokens, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Running NER models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CAMEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_camel(tokens, model_name):\n",
    "    #print(tokens)\n",
    "    ner = NERecognizer(model_name)\n",
    "\n",
    "    y_pred = []\n",
    "    y_tkns = []\n",
    "    for token in tokens:\n",
    "        pred = []\n",
    "        tkns = []       \n",
    "        sentence = simple_word_tokenize(\" \".join(token))\n",
    "        pred = ner.predict_sentence(sentence)\n",
    "        y_pred.append(pred)\n",
    "        y_tkns.append(sentence)\n",
    "    return y_tkns, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FARASA \n",
    "https://farasa.qcri.org/NER/\n",
    "\n",
    "`TODO` request an API key through FARASA website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "url = 'https://farasa.qcri.org/webapi/ner/'\n",
    "api_key = \"<PUT API KEY HERE>\"\n",
    "\n",
    "def detect_ner(text):\n",
    "    payload = {'text': text, 'api_key': api_key}\n",
    "    data = requests.post(url, data=payload)\n",
    "    if \"could not NER\" == data.content.decode():\n",
    "        result = \"could not NER\"\n",
    "    else:\n",
    "        result = json.loads(data.text)['text']\n",
    "    return result\n",
    "\n",
    "def run_farasa(tokens):\n",
    "    y_pred = []\n",
    "    y_tkns = []\n",
    "    for token in tokens:\n",
    "        pred = []\n",
    "        tkns = []\n",
    "        res = detect_ner(\" \".join(token))\n",
    "        if res == \"could not NER\":\n",
    "            print(\"could not NER: \" + \" \".join(token))\n",
    "            pred = ['O']*len(token)\n",
    "            tkns = token\n",
    "            continue\n",
    "        for p in res:\n",
    "            splits = p.split('/')\n",
    "            pred.append(splits[1])\n",
    "            tkns.append(splits[0])\n",
    "        y_pred.append(pred)\n",
    "        y_tkns.append(tkns)\n",
    "    return y_tkns, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Write Predictions to files in BIO-like format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_entities(labels):\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels[i])):\n",
    "            if labels[i][j] not in [\"B-LOC\", \"I-LOC\", \"O\"]:\n",
    "                labels[i][j] = \"O\"\n",
    "            \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_predictions(output_path, tokens, labels):\n",
    "    writer = open(output_path, 'w', encoding='utf-8', newline=\"\")\n",
    "    \n",
    "    for i in range(len(labels)):\n",
    "        t = [x for x in tokens[i]]\n",
    "        for j in range(len(labels[i])):\n",
    "            writer.write(t[j] + \"\\t\" + labels[i][j] + \"\\n\")\n",
    "        writer.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driver Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"<path to IDRISI data directory>\\\\IDRISI\\\\data\\\\LMR\\\\\"\n",
    "events = [\"beirut_explosion_2020\", \"cairo_bombing_2019\", \"covid_2019\", \"dragon_storms_2020\",\n",
    "          \"hafr_albatin_floods_2019\", \"jordan_floods_2018\", \"kuwait_floods_2018\"]\n",
    "\n",
    "ner = 'FARASA' #or 'CaMEL'\n",
    "\n",
    "models = ['bert-base-arabic-camelbert-ca-ner', 'bert-base-arabic-camelbert-da-ner', \n",
    "          'bert-base-arabic-camelbert-mix-ner', 'bert-base-arabic-camelbert-msa-ner']         \n",
    "\n",
    "for case in ['random', 'timebased']:\n",
    "    for event in events:\n",
    "        in_path = path + \"AR\\gold-\" + case + \"-bilou\\\\\" + event \n",
    "        test_path = in_path + \"\\\\dev.txt\"\n",
    "        x_true, y_true = read_annotated_data(test_path)\n",
    "        # TODO: you can pick any of the model names in the `models` list above\n",
    "        if ner == 'CaMEL':\n",
    "            x_pred, y_pred = run_camel(x_true, \"CAMeL-Lab/bert-base-arabic-camelbert-mix-ner\")\n",
    "            y_pred = remove_entities(y_pred) #to remove non-LOC entities\n",
    "        else:\n",
    "            x_pred, y_pred = run_farasa(x_true)\n",
    "        \n",
    "        out_path = path + \"AR\\gold-\" + case + \"-\" + event + \"-\" + ner + \"-predictions.txt\"\n",
    "        dump_predictions(out_path, x_pred, y_pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
